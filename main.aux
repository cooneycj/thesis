\relax 
\bibstyle{apalike}
\citation{DayanAbbott2001a}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Spike Trains}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Spike Train Metrics}{2}}
\citation{VanRossum2001a}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Van Rossum metric}{3}}
\citation{VictorPurpura1997a}
\citation{BialekEtAl1998a}
\citation{GillespieHoughton2009a}
\citation{Shannon1948a}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Information Theory}{4}}
\citation{Newman2010a}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Clustering methods in Spike Train Analysis}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{Newman2006b}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Modularity}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The advantage to clustering a network correctly is seen here. Both of these networks have the same nodes and links, and so are the same network, but they look vastly different because the diagram on the left has been clustered to maximise modularity.}}{8}}
\newlabel{netclus}{{2.1}{8}}
\citation{BenderCanfield1978a}
\citation{Bollobas1980a}
\citation{Newman2010a}
\newlabel{probki}{{2.4}{9}}
\citation{Newman2006a}
\newlabel{NewMod}{{2.8}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Newman's eigenvalue algorithm}{10}}
\newlabel{ssMod}{{2.11}{11}}
\citation{Zachary1977a}
\citation{Newman2006a}
\citation{Newman2006a}
\citation{Newman2006a}
\citation{NewmanGirvan2004a}
\citation{Humphries2011a}
\citation{Newman2006a}
\citation{NewmanGirvan2004a}
\citation{Pizzuti2008a}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}New network clustering algorithms}{14}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces This is Newman's eigenvalue algorithm for maximising the modularity of a network.}}{15}}
\newlabel{algo-split}{{1}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Genetic algorithm}{16}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces An example of a generic genetic algorithm.}}{17}}
\newlabel{genal}{{2}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Simulated annealing}{18}}
\citation{Zachary1977a}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}$k$-medoids clustering}{19}}
\citation{JulienneHoughton2012a}
\citation{NarayanEtAl2006b}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Clustering responses with modularity}{21}}
\citation{Humphries2011a}
\citation{SinghLesica2010a}
\citation{Newman2010a}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Mapping information flow in a simulated network of neurons}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}The bibliographic network}{24}}
\citation{SinghLesica2010a}
\citation{Schreiber2000a}
\citation{BialekEtAl1998a}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Incremental mutual information}{25}}
\citation{BretteGerstner2005a}
\citation{HopfieldHerz1995a}
\citation{HodgkinHuxley1952a}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Numerical testing}{26}}
\citation{SinghLesica2010a}
\citation{Newman2006a}
\citation{NewmanGirvan2004a}
\newlabel{adjmat}{{2.25}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Bibliographic coupling}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces An example of the first step in k-medoids clustering: (a) Medoids are initially selected at random and the first clustering puts each point in the cluster of the closest medoid. Then we choose the point in the cluster that will give the lowest total distance to other points, and choose that as the new medoid. (b) Finally, we re-cluster each point to go in the cluster of the closest medoid to it.}}{28}}
\newlabel{kmed}{{2.2}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The network model was based on the schematic shown here. All simulated neurons in the recurrent layer were aEIF neurons. The connection probability between two nodes at random was $0.1$, connections along arrows in the diagram occurred with probability $0.8$, and connections from the noise layer to the recurrent layer occurred with probability $0.2$.}}{29}}
\newlabel{modelnetwork}{{2.3}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces  A standard representation of the directed network above, and the connection matrix of the recurrent layer of aEIF neurons below.}}{30}}
\newlabel{netwm}{{2.4}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  The connection matrix calculated from the peak IMI of the neurons, as the amplitude of the individual neurons in the noise layer increased from $1$ mV to $16$ mV. Note that the IMI actually becomes more discriminating as the noise level increases.}}{31}}
\newlabel{imires}{{2.5}{31}}
\citation{VanRossum2001a}
\citation{VictorPurpura1996a}
\citation{KreuzEtAl2007a}
\citation{Kreuzetal2011a}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Spike Train Metrics}{32}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{Kreuzetal2011a}
\citation{Kreuzetal2011a}
\citation{Kreuzetal2011}
\citation{Kreuzetal2011}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Single-unit recordings}{34}}
\citation{Kreuzetal2011}
\citation{VictorPurpura1997}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Extension to multi-unit recordings}{36}}
\citation{HoughtonSen2008}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Testing on data}{37}}
\citation{HoughtonSen2008}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}ISI distance}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Single unit recordings}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Initial extension to multi-unit recordings}{38}}
\citation{HoughtonSen2008}
\citation{Kreuzetal2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Numerical tests}{41}}
\citation{Kreuzetal2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Alternative extensions to the multi-unit case}{42}}
\newlabel{pop}{{3.23}{42}}
\newlabel{av}{{3.24}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Adaptive SPIKE \& ISI distances}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces An example of how to calculate the gaps between spikes. If the circles represent spikes from $\mathbf  {X}$ and crosses represent spikes from $\mathbf  {Y}$, then in the picture above, the distance $k$ is simply the cost of relabelling a spike. We also see that the gaps are not necessarily symmetric.}}{46}}
\newlabel{fig:gaps2}{{3.1}{46}}
\citation{OlshausenField2004}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}A simple neuron model}{47}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{lam}{{4.1}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Estimating the firing rate $r(t)$}{48}}
\newlabel{p}{{4.2}{48}}
\citation{vanRossum2001}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  This figure shows the ratio of the predicted value for $\tau $ in an exponential model over the empirical optimised value $\tau _o$.}}{50}}
\newlabel{predovertauopt}{{4.1}{50}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Markov Process}{51}}
\newlabel{dg}{{4.23}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Estimating the rate function $r(t)$}{54}}
\newlabel{abcd}{{4.29}{55}}
\newlabel{rate}{{4.35}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Change in probability when a spike arrives}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Calculating the ISI distribution from the estimated rate function}{57}}
\newlabel{int}{{4.43}{58}}
\citation{SenEtAl2001a}
\citation{Massey1951a}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Testing on data}{59}}
\citation{Massey1951a}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces  The Kolmogorov-Smirnov test statistic $D_n$ for (a) the exponential distribution, (b) the hyperexponential distribution with two modes, and (c) the hyperexponential distribution with three modes. The mean of the $p<0.05$ critical value is indicated by the broken line.}}{61}}
\newlabel{exphehe3}{{4.2}{61}}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{63}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{BenderCanfield1978a}{Bender and Canfield, 1978}
\bibcite{Bollobas1980a}{Bollob{\'a}s, 1980}
\bibcite{BretteGerstner2005a}{Brette and Gerstner, 2005}
\bibcite{DayanAbbott2001a}{Dayan and Abbott, 2001}
\bibcite{GillespieHoughton2009a}{Gillespie and Houghton, 2011}
\bibcite{HodgkinHuxley1952a}{Hodgkin and Huxley, 1952}
\bibcite{HopfieldHerz1995a}{Hopfield and Herz, 1995}
\bibcite{HoughtonSen2008}{Houghton and Sen, 2008}
\bibcite{Humphries2011a}{Humphries, 2011}
\bibcite{JulienneHoughton2012a}{Julienne and Houghton, 2013}
\bibcite{Kreuzetal2009}{Kreuz et\nobreakspace  {}al., 2009}
\bibcite{Kreuzetal2011a}{Kreuz et\nobreakspace  {}al., 2011a}
\bibcite{Kreuzetal2011}{Kreuz et\nobreakspace  {}al., 2011b}
\bibcite{KreuzEtAl2007a}{Kreuz et\nobreakspace  {}al., 2007}
\bibcite{Massey1951a}{Massey\nobreakspace  {}Jr, 1951}
\bibcite{NarayanEtAl2006b}{Narayan et\nobreakspace  {}al., 2006}
\bibcite{Newman2006b}{Newman, 2006a}
\bibcite{Newman2006a}{Newman, 2006b}
\bibcite{Newman2010a}{Newman, 2010}
\bibcite{NewmanGirvan2004a}{Newman and Girvan, 2004}
\bibcite{OlshausenField2004}{Olshausen and Field, 2004}
\bibcite{Pizzuti2008a}{Pizzuti, 2008}
\bibcite{Schreiber2000a}{Schreiber, 2000}
\bibcite{SenEtAl2001a}{Sen et\nobreakspace  {}al., 2001}
\bibcite{Shannon1948a}{Shannon, 1948}
\bibcite{SinghLesica2010a}{Singh and Lesica, 2010}
\bibcite{BialekEtAl1998a}{Strong et\nobreakspace  {}al., 1998}
\bibcite{VanRossum2001a}{van Rossum, 2001a}
\bibcite{vanRossum2001}{van Rossum, 2001b}
\bibcite{VictorPurpura1996a}{Victor and Purpura, 1996}
\bibcite{VictorPurpura1997a}{Victor and Purpura, 1997a}
\bibcite{VictorPurpura1997}{Victor and Purpura, 1997b}
\bibcite{Zachary1977a}{Zachary, 1977}
